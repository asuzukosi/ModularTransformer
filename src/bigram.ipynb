{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using simple bigram architecture for building language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"wizard_of_oz.txt\", \"r+\", encoding=\"utf-8\") as file:\n",
    "    data = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208602\n",
      "﻿The Project Gutenberg eBook of The Wonderful Wizard of Oz, by L. Frank Baum\n",
      "\n",
      "This eBook is for the use of anyone anywhere in the United States and\n",
      "most other parts of the world at no cost and with al\n"
     ]
    }
   ],
   "source": [
    "print(len(data))\n",
    "print(data[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '#', '&', '(', ')', '*', ',', '-', '.', '0', '1', '2', '3', '5', '8', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '—', '‘', '’', '“', '”', '\\ufeff']\n",
      "81\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(set(data))\n",
    "print(chars)\n",
    "print(len(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[56, 53, 60, 60, 63]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_to_int = { ch:i for i, ch in enumerate(chars)}\n",
    "int_to_str = { i:ch for i, ch in enumerate(chars)}\n",
    "\n",
    "encode = lambda s : [ str_to_int[c] for c in s]\n",
    "decode = lambda i : ''.join([int_to_str[e] for e in i])\n",
    "\n",
    "encode(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode([56, 53, 60, 60, 63])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([80, 40, 56, 53,  1, 36, 66, 63, 58, 53, 51, 68,  1, 27, 69, 68, 53, 62,\n",
      "        50, 53, 66, 55,  1, 53, 22, 63, 63, 59,  1, 63, 54,  1, 40, 56, 53,  1,\n",
      "        43, 63, 62, 52, 53, 66, 54, 69, 60,  1, 43, 57, 74, 49, 66, 52,  1, 63,\n",
      "        54,  1, 35, 74,  8,  1, 50, 73,  1, 32, 10,  1, 26, 66, 49, 62, 59,  1,\n",
      "        22, 49, 69, 61,  0,  0, 40, 56, 57, 67,  1, 53, 22, 63, 63, 59,  1, 57,\n",
      "        67,  1, 54, 63, 66,  1, 68, 56, 53,  1])\n"
     ]
    }
   ],
   "source": [
    "# character and word level tokenizers\n",
    "data = torch.tensor(encode(data), dtype=torch.long)\n",
    "print(data[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation and training splits\n",
    "n = int(0.8 *len(data))\n",
    "\n",
    "train_data = data[:n]\n",
    "test_data = data[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple bigram language model\n",
    "block_size = 8\n",
    "batch_size = 4\n",
    "\n",
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([80, 40, 56, 53,  1, 36, 66, 63]),\n",
       " tensor([40, 56, 53,  1, 36, 66, 63, 58]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is :  tensor([80]) then target is  tensor(40)\n",
      "when input is :  tensor([80, 40]) then target is  tensor(56)\n",
      "when input is :  tensor([80, 40, 56]) then target is  tensor(53)\n",
      "when input is :  tensor([80, 40, 56, 53]) then target is  tensor(1)\n",
      "when input is :  tensor([80, 40, 56, 53,  1]) then target is  tensor(36)\n",
      "when input is :  tensor([80, 40, 56, 53,  1, 36]) then target is  tensor(66)\n",
      "when input is :  tensor([80, 40, 56, 53,  1, 36, 66]) then target is  tensor(63)\n",
      "when input is :  tensor([80, 40, 56, 53,  1, 36, 66, 63]) then target is  tensor(58)\n"
     ]
    }
   ],
   "source": [
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    \n",
    "    print(\"when input is : \", context, \"then target is \", target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-36,  80,  90,  79, -35])\n"
     ]
    }
   ],
   "source": [
    "randints = torch.randint(-100, 100, (5, ))\n",
    "print(randints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "zeros = torch.zeros((2, 3))\n",
    "print(zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "ones = torch.ones((3, 4))\n",
    "print(ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "i = torch.empty((3, 2))\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2, 3, 4],\n",
      "        [5, 6, 7, 8, 9]])\n"
     ]
    }
   ],
   "source": [
    "i = torch.reshape(torch.arange(10), shape=(2, 5))\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.0000, 3.2500, 4.5000, 5.7500, 7.0000])\n"
     ]
    }
   ],
   "source": [
    "i = torch.linspace(2, 7, steps=5)\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0000e-10, 1.0000e-05, 1.0000e+00, 1.0000e+05, 1.0000e+10])\n"
     ]
    }
   ],
   "source": [
    "i = torch.logspace(start=-10, end=10, steps=5)\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 0, 1, 0, 1, 1, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "probabilities = torch.tensor([0.1, 0.9])\n",
    "samples = torch.multinomial(probabilities, num_samples=10, replacement=True)\n",
    "print(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4, 5])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.tensor([1, 2, 3, 4])\n",
    "tensor = torch.cat((tensor, torch.tensor([5])), dim=0)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0., 0.],\n",
      "        [1., 1., 0., 0., 0.],\n",
      "        [1., 1., 1., 0., 0.],\n",
      "        [1., 1., 1., 1., 0.],\n",
      "        [1., 1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.tril(torch.ones(5, 5))\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1., 1.],\n",
      "        [0., 1., 1., 1., 1.],\n",
      "        [0., 0., 1., 1., 1.],\n",
      "        [0., 0., 0., 1., 1.],\n",
      "        [0., 0., 0., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.triu(torch.ones(5, 5))\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(split):\n",
    "    data = train_data if split == \"train\"  else test_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size, ))\n",
    "    \n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[63, 62, 53,  1, 38, 63, 63, 61],\n",
       "        [53, 62, 52,  8,  1, 49, 62, 52],\n",
       "        [57, 68,  8,  1, 67, 49, 73, 57],\n",
       "        [68, 56, 53,  1, 23, 63, 71, 49]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = get_batch(\"train\")\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiGram(nn.Module):\n",
    "    def __init__(vocab_size, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "        \n",
    "        \n",
    "    def forward(self, index, targets):\n",
    "        logits = self.token_embedding_table(index)\n",
    "        \n",
    "        B, T, C = logits.shape\n",
    "        \n",
    "        logits = logits.view(B*T, C)\n",
    "        targets = targets.view(B*T)\n",
    "        \n",
    "        loss = F.cross_entropy(logits, targets)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
