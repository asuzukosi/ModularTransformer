{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using simple bigram architecture for building language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"wizard_of_oz.txt\", \"r+\", encoding=\"utf-8\") as file:\n",
    "    data = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208602\n",
      "﻿The Project Gutenberg eBook of The Wonderful Wizard of Oz, by L. Frank Baum\n",
      "\n",
      "This eBook is for the use of anyone anywhere in the United States and\n",
      "most other parts of the world at no cost and with al\n"
     ]
    }
   ],
   "source": [
    "print(len(data))\n",
    "print(data[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '#', '&', '(', ')', '*', ',', '-', '.', '0', '1', '2', '3', '5', '8', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '—', '‘', '’', '“', '”', '\\ufeff']\n",
      "81\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(set(data))\n",
    "print(chars)\n",
    "print(len(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[56, 53, 60, 60, 63]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_to_int = { ch:i for i, ch in enumerate(chars)}\n",
    "int_to_str = { i:ch for i, ch in enumerate(chars)}\n",
    "\n",
    "encode = lambda s : [ str_to_int[c] for c in s]\n",
    "decode = lambda i : ''.join([int_to_str[e] for e in i])\n",
    "\n",
    "encode(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode([56, 53, 60, 60, 63])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([80, 40, 56, 53,  1, 36, 66, 63, 58, 53, 51, 68,  1, 27, 69, 68, 53, 62,\n",
      "        50, 53, 66, 55,  1, 53, 22, 63, 63, 59,  1, 63, 54,  1, 40, 56, 53,  1,\n",
      "        43, 63, 62, 52, 53, 66, 54, 69, 60,  1, 43, 57, 74, 49, 66, 52,  1, 63,\n",
      "        54,  1, 35, 74,  8,  1, 50, 73,  1, 32, 10,  1, 26, 66, 49, 62, 59,  1,\n",
      "        22, 49, 69, 61,  0,  0, 40, 56, 57, 67,  1, 53, 22, 63, 63, 59,  1, 57,\n",
      "        67,  1, 54, 63, 66,  1, 68, 56, 53,  1])\n"
     ]
    }
   ],
   "source": [
    "# character and word level tokenizers\n",
    "data = torch.tensor(encode(data), dtype=torch.long)\n",
    "print(data[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation and training splits\n",
    "n = int(0.8 *len(data))\n",
    "\n",
    "train_data = data[:n]\n",
    "test_data = data[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple bigram language model\n",
    "block_size = 8\n",
    "\n",
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([80, 40, 56, 53,  1, 36, 66, 63]),\n",
       " tensor([40, 56, 53,  1, 36, 66, 63, 58]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is :  tensor([80]) then target is  tensor(40)\n",
      "when input is :  tensor([80, 40]) then target is  tensor(56)\n",
      "when input is :  tensor([80, 40, 56]) then target is  tensor(53)\n",
      "when input is :  tensor([80, 40, 56, 53]) then target is  tensor(1)\n",
      "when input is :  tensor([80, 40, 56, 53,  1]) then target is  tensor(36)\n",
      "when input is :  tensor([80, 40, 56, 53,  1, 36]) then target is  tensor(66)\n",
      "when input is :  tensor([80, 40, 56, 53,  1, 36, 66]) then target is  tensor(63)\n",
      "when input is :  tensor([80, 40, 56, 53,  1, 36, 66, 63]) then target is  tensor(58)\n"
     ]
    }
   ],
   "source": [
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    \n",
    "    print(\"when input is : \", context, \"then target is \", target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
